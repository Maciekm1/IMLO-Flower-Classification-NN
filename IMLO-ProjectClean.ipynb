{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 * 112 * 112, 2056)\n",
    "        self.fc2 = nn.Linear(2056, 512)\n",
    "        self.fc3 = nn.Linear(512, 102)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, 3 * 112 * 112)\n",
    "\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    Resize((128, 128)),\n",
    "    RandomResizedCrop(size=(112, 112), scale=(0.8, 1.0)),\n",
    "    ToTensor(),\n",
    "    #Normalize(mean=[0.4330, 0.3819, 0.2964], std=[0.2555, 0.2056, 0.2175])\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    Resize((112, 112)),\n",
    "    ToTensor(),\n",
    "    #Normalize(mean=[0.4330, 0.3819, 0.2964], std=[0.2555, 0.2056, 0.2175]),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    Resize((112, 112)),\n",
    "    ToTensor(),\n",
    "    #Normalize(mean=[0.4330, 0.3819, 0.2964], std=[0.2555, 0.2056, 0.2175]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='train', download=True, transform=train_transform)\n",
    "val_data = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='val', download=True, transform=val_transform)\n",
    "test_data = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='test', download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create Variables To Tracks Things\n",
    "epochs = 200\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 5  # How many epochs to wait after val loss has stopped improving\n",
    "min_val_loss = float('inf')  # Initialize to infinity\n",
    "stale_epochs = 0  # Counter for epochs without improvement\n",
    "\n",
    "# For Loop of Epochs\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    # Update the train_loader with the new transformations\n",
    "    #current_transform = update_transform(i)  # Get the updated transform for the current epoch\n",
    "    #train_data.transform = current_transform  # Update the transform in the dataset\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)  # Recreate the DataLoader with the updated dataset\n",
    "\n",
    "    # Train\n",
    "    for b, (X_train, y_train) in enumerate(train_loader, 1):\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        y_pred = model(X_train)  # get predicted values from the training set. Not flattened 2D\n",
    "        loss = criterion(y_pred, y_train)  # how off are we? Compare the predictions to correct answers in y_train\n",
    "\n",
    "        predicted = torch.max(y_pred.data, 1)[\n",
    "            1]  # add up the number of correct predictions. Indexed off the first point\n",
    "        batch_corr = (predicted == y_train).sum()  # how many we got correct from this batch. True = 1, False=0, sum those up\n",
    "        trn_corr += batch_corr  # keep track as we go along in training.\n",
    "\n",
    "        # Update our parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "            # Print out some results\n",
    "        if b % 64 == 0:\n",
    "            print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
    "\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    # Test\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for b, (X_test, y_test) in enumerate(val_loader):\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            val_loss += criterion(y_val, y_test).item()  # Sum up the loss from each batch\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)  # Calculate the average loss\n",
    "    loss = criterion(y_val, y_test)\n",
    "\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        stale_epochs = 0  # Reset the stale epochs counter\n",
    "    else:\n",
    "        stale_epochs += 1  # Increment the stale epochs counter\n",
    "        if stale_epochs >= patience:\n",
    "            print(f'Stopping early at epoch {i} due to overfitting.')\n",
    "            break  # Break out of the loop\n",
    "\n",
    "    print(f'Epoch: {i} Validation Loss: {avg_val_loss}')\n",
    "\n",
    "current_time = time.time()\n",
    "total = current_time - start_time\n",
    "print(f'Training Took: {total / 60} minutes!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
