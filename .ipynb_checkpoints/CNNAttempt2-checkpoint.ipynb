{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63875db0-90ec-466c-af1d-eee251cfeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fad6a17-5b70-4860-84f1-a9e5a2ccbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "EPOCH_PATIENCE = 15\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.008\n",
    "NUM_CLASSES = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264b123f-c42e-471c-9fc6-947b2d3f2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8daca48b-66d0-4c38-b8e2-131499234040",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4330, 0.3819, 0.2964], std=[0.2555, 0.2056, 0.2175])\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4330, 0.3819, 0.2964], std=[0.2555, 0.2056, 0.2175]),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4330, 0.3819, 0.2964], std=[0.2555, 0.2056, 0.2175]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bade3232-b6b6-47ef-9078-81c09ce3829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='train', download=True, transform=train_transform)\n",
    "val_data = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='val', download=True, transform=val_transform)\n",
    "test_data = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='test', download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76793e50-fa13-4465-a6af-d77526cb6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "228a7864-c1c2-4a69-b7e8-71e4fd3a082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4330, 0.3819, 0.2964])\n",
      "Std: tensor([0.2587, 0.2093, 0.2210])\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to resize the images and convert them to tensors\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Load the dataset with the defined transform\n",
    "dataset = datasets.Flowers102(root=\"/Users/maciek/cnn_data\", split='train', download=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Function to calculate mean and std\n",
    "def calculate_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "\n",
    "    for (images, _) in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# Calculate mean and std\n",
    "mean, std = calculate_mean_std(loader)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a9780-76c3-4172-80b3-cb5680a6ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "\t#  determine what layers and their order in CNN object \n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=4, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.max_pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc6 = nn.Linear(1024, 512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(512, 256)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc8 = nn.Linear(256, NUM_CLASSES)\n",
    "    \n",
    "    # progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.max_pool5(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.dropout6(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.relu6(out)\n",
    "\n",
    "        out = self.dropout7(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.relu7(out)\n",
    "\n",
    "        out = self.fc8(out)  # final logits\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeaabf3-f70b-48f4-ab30-073a58aaad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeuralNet().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a10646-8772-4f30-bbfd-72aea62bb136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4266b1-3319-4557-b712-b4291619522e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa33fd-6af5-44a8-a4a3-de327c598d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cad613-9ff1-4b66-b3e6-87ede2a4d2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673fd05-6e7c-4283-9356-183a92c13e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea02be9-b9d4-404d-956f-5e7f8e7ef92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c478727-c9f0-4046-84be-44f1a0b1e19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52792f-6b9b-47bc-a0f7-d609bc27b1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f5d09-bc41-43b4-bc4f-38db7031c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5200daf-7c56-475f-b151-01c53e0cf91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f01344-a776-4597-96d2-d22f19b7334f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183ae3e-ae9d-41ed-a657-41f2eb01c8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096a539-8148-4b82-93b5-08b83fcf185e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b95d3e-eaf4-407d-8870-ded046d1bbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a1ce1-31d8-4cb3-8aa4-d066687bd2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a93f07-2152-4d25-9420-988f05457185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
